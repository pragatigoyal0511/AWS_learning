How Compute Evolved in AWS?

| Stage                      | What You Manage                         | Example    | What Problem It Solved             | What Problem Still Remained                  |
| -------------------------- | --------------------------------------- | ---------- | ---------------------------------- | -------------------------------------------- |
| **EC2 (Virtual Machines)** | You manage **servers**                  | Amazon EC2 | No need for physical hardware      | But you still patch OS, scale, monitor, etc. |
| **Containers (ECS/EKS)**   | You manage **apps + container runtime** | ECS / EKS  | Easier app packaging, faster start | Still need to manage cluster, scaling, cost  |
| **Serverless**             | You manage **only code**                | AWS Lambda | No infrastructure to manage        | Limited control over runtime, timeouts       |



So, Serverless = next level of simplification.

Why Serverless Came?
Even with containers, you still had to:

Run EC2s or clusters under ECS/EKS.
Pay for them even when apps are idle.
Handle scaling up/down.
Monitor CPU/memory and tune sizes.

Developers said:
“I just want to run my function or app logic, not manage servers or containers!”

AWS listened — and introduced Serverless Compute, starting with AWS Lambda.


What “Serverless” Actually Means?
“Serverless” doesn’t mean no servers exist 😄
It means:

You don’t manage or even see the servers. AWS does everything for you.
No provisioning EC2s.
No container clusters.
No scaling setup.
You only upload your code.

AWS:
Decides where to run it.
Automatically scales it up/down.
Charges only when it runs.


->Example to Understand:

->Before (with EC2)
You rent a computer 24x7.
Even if you get 1 visitor, you still pay for the whole day.
You install OS, Python, security patches, etc.

🧩 With Containers

You rent 1 computer and run multiple apps.
Better utilization, but still always on.
You still manage the container cluster.

🧩 With Serverless (Lambda)
You don’t rent a computer at all.
You just say: “Run this function when user clicks a button.”
AWS runs it for a few milliseconds, then stops.
You pay only for those milliseconds.

✅ No idle cost
✅ No patching
✅ Auto scale to millions instantly


5️⃣ Example: AWS Lambda (Serverless Compute)

You upload your code (in Python, Node.js, Java, etc.).
You define a trigger (API Gateway, S3 upload, DynamoDB event, etc.).
AWS Lambda runs your code only when triggered.

You pay per request + compute time (milliseconds).

Example:

When a user uploads an image to S3:
S3 triggers a Lambda.
Lambda resizes the image.
Lambda stops.

You pay for only those few seconds.


When Not to Use Serverless?
It’s not perfect — avoid it when:

You need long-running tasks (since Lambda has max 15-min runtime).
You need custom OS/network setups.
You need super low-latency responses (for high-frequency trading, etc.).
You need full control over the environment.

Then you go back to ECS/EKS/EC2.



why is user responsible for os security updates in ec2 when it comes installed?
How EC2 works

Remember:
EC2 is Infrastructure as a Service (IaaS).
AWS provides virtual hardware, networking, and the option to choose an operating system.
But once the OS is installed, you are effectively running a full computer — like a regular laptop or server.

That means:
AWS doesn’t know what software you install.
AWS doesn’t automatically maintain your OS or apps.

So the responsibility for keeping the OS secure falls on you.


-> AWS fargate
AWS Fargate is a serverless compute engine for containers.

Jaise containers ko run karne ke liye EC2 instance pe deploy karte hain..EC2 instance is the platform, toh usi tarah serverless compute platform is AWS fargate.

1️⃣ First — Recap: How Containers Run Normally

When you use ECS or EKS, containers need some compute power underneath to actually run.
Usually, this means:

You launch a few EC2 instances (these are the “container hosts”).
ECS or EKS then places your containers on those EC2s.
You manage:
EC2 instance sizes.
Patching OS.
Scaling up/down.
Monitoring utilization.

So even with containers, you’re still managing servers behind the scenes.

2️⃣ The Problem

Developers said:

“We love containers! But we don’t want to manage EC2s or clusters anymore — we just want our containers to run automatically.”

That’s where AWS Fargate comes in.

3️⃣ What is AWS Fargate?

AWS Fargate is a serverless compute engine for containers.
That means:
You run containers without managing any EC2 servers.

AWS automatically:
Provides the compute infrastructure.
Launches your containers.
Scales them up/down.
Manages patching, networking, security updates.

You only tell:
“Here’s my container image.”
“It needs 2 vCPUs and 4 GB RAM.”

…and AWS Fargate runs it. You pay only for the CPU/memory your container actually uses.

🧩 4️⃣ Fargate Works With ECS & EKS

Fargate isn’t a separate orchestrator — it’s a compute option inside ECS or EKS.



So you choose whether your containers run on:
Your own EC2 instances, or
Fargate (AWS-managed).



6️⃣ Example

Let’s say you have a web app container:

You build the container → push it to Amazon ECR. Elastic Compute Registry

You define in ECS:

Which image to run.
How much CPU/memory.
How many copies (tasks).

You choose Fargate launch type.

AWS:
Allocates compute.
Runs the container.
Monitors and scales it.

Charges you only for the time it’s running.

👉 You never touch EC2 at all.

In One Line:
Fargate = “Run my containers, don’t ask me about servers.”


-> AWS Lambda

What AWS Lambda Is

👉 AWS Lambda is a serverless compute service that lets you run your code without managing servers or containers.

You only give your function (small piece of code) —
AWS handles:

The servers,
Scaling,
Execution,
Availability, and
Billing (only when it runs).

You never think about infrastructure — not even containers (jo hum fargate mein dekhte hain)


2️⃣ How It Works

You:

Write a function (e.g. in Python, Node.js, Java, etc.).

Upload it to AWS Lambda.
Tell AWS when it should run — like:
When an image is uploaded to S3.
When someone calls an API Gateway endpoint.
When a new record appears in DynamoDB.
AWS automatically runs your code for just that event.

When done → Lambda stops → you stop paying.


✅ No servers
✅ No clusters
✅ Pay only for the seconds used

6️⃣ When to Use AWS Lambda?

✅ Event-driven workloads
Like:
Upload to S3 → process file
API request → return data
DynamoDB insert → trigger computation

✅ Short tasks
Each Lambda runs max 15 minutes.

✅ Automatic scaling
Handles 1 request or 1 million — automatically.

✅ Cost efficiency
Pay only for run time — not idle time.
